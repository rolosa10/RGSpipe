{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0999dfdd",
   "metadata": {},
   "source": [
    "This notebook aims to process each one of the splitted mp4 frames that are used to train the Martinez et al NN and see if MediaPipe is capable to detect correctly the 2D keypoints besides the drawbacks of Dustmask, Bodysuit and people in the background. \n",
    "\n",
    "The objective is to process each one of the frames and then delete manually the ones that are not detected propely. Then, the remaining frames will be used in a final analysis of the final solution to check if the proposed pipeline (MediaPipe + Martinez) is accurate enough to replace Kinect "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e785f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c869875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.spatial import distance\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e6ebc",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2644f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_numbers_variables = {0:'left_shoulder',\n",
    "                             1:'right_shoulder',\n",
    "                             2:'left_elbow',\n",
    "                             3:'right_elbow',\n",
    "                             4:'left_wrist',\n",
    "                             5:'right_wrist'}\n",
    "\n",
    "def split_2d_coordinates_array(coordinates_array):\n",
    "    m = 0\n",
    "    r = 2\n",
    "    frame_coordinates = []\n",
    "    for j in range(0,int(len(coordinates_array)/2)):\n",
    "        frame_coordinates.append(coordinates_array[m:r])\n",
    "        m = r\n",
    "        r = r+2\n",
    "    return(np.array(frame_coordinates))\n",
    "\n",
    "def mediapipe_inference(frame):\n",
    "    results = pose.process(frame)\n",
    "    frame_list1 = []\n",
    "    start_index = 0\n",
    "    if results.pose_landmarks:\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            #If landmark visibility is not 0.5 save a NaN and this value will be replaced by the previous recorded value\n",
    "            #Reference & first value is the callibraition picture \n",
    "            \n",
    "            if landmark.visibility>0.5:\n",
    "                if start_index in indices_landmark_interest:\n",
    "                    image_hight, image_width, _ = frame.shape\n",
    "                    frame = cv2.circle(frame, (int(landmark.x*image_width), int(landmark.y*image_hight)), radius=5, color = (0,255,0), thickness=-1)   \n",
    "                    frame_list1.append(landmark.x*image_width)\n",
    "                    frame_list1.append(landmark.y*image_hight) \n",
    "                    start_index = start_index+1\n",
    "                else:\n",
    "                    start_index = start_index+1\n",
    "            else: \n",
    "                start_index = start_index+1\n",
    "    return(frame_list1,frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bdcf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_landmark_interest = [11, 12, 13, 14, 15 ,16]\n",
    "number_of_keypoints_to_detect = len(indices_landmark_interest)\n",
    "\n",
    "#names_kinect = ['Xavi','Adri','Mireia']\n",
    "names_kinect = ['Xavi','Adri']\n",
    "numbers = ['01','02','03','04','05']\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(model_complexity=0,min_detection_confidence=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c43d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names_kinect:\n",
    "    for number in numbers:\n",
    "        filenames = glob('../data/Webcam/'+str(name)+'/'+str(name)+str(number)+'/mp4_splitted/*.jpg')\n",
    "        df = pd.DataFrame(columns=np.arange(0,(number_of_keypoints_to_detect*2)+1))\n",
    "        for filename in filenames:\n",
    "            image = cv2.imread(filename)\n",
    "            timecode = float(filename.split('/')[-1].split('_')[-1].split('.jpg')[0])\n",
    "            \n",
    "#             #Defining the blurr filter intensity\n",
    "#             blurred_img = cv2.GaussianBlur(image, (201, 201), 0)\n",
    "#             #Generate a black image with the same shape as the image that we want to blurr\n",
    "#             mask = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "#             #Define bottom polytgon by its corners\n",
    "#             contours1 = np.array([[0,1080],[0,820],[580,670],[1300,670],[1920,820],[1920,1080]])\n",
    "#             #Draw the previous defined polygon in mask and fill it with white\n",
    "#             mask = cv2.fillPoly(mask, pts = [contours1], color =(255,255,255))\n",
    "#             contours2 = np.array([[580,100],[1300,100],[1300,670],[580,670]])\n",
    "#             mask = cv2.fillPoly(mask, pts = [contours2], color =(255,255,255))\n",
    "#             #Just keep white points normal and blurr black points\n",
    "#             image = np.where(mask==np.array([255, 255, 255]), image, blurred_img)\n",
    "    \n",
    "            detected_keypoints, frame = mediapipe_inference(image)\n",
    "            detected_keypoints.insert(0,timecode)\n",
    "            df = df.append(pd.DataFrame(np.array(detected_keypoints).reshape(1,-1)))\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "            cv2.imwrite('../data/Webcam/'+str(name)+'/'+str(name)+str(number)+'/mp4_splitted_MPlabeled/'+filename.split('\\\\')[-1],frame)\n",
    "        df.to_csv('../data/Webcam/'+str(name)+'/'+str(name)+str(number)+'/mp4_splitted_MPlabeled/'+str(name)+'_'+str(number)+'_mp_output_all.csv',header=None,index=None,sep=',')\n",
    "                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
